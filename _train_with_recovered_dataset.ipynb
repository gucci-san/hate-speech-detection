{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [SEP]付きで学習できるかどうか試すnotebook\n",
    "\n",
    "* とりあえずduplicatedはそのまま\n",
    "* text_picked==0はtextを流用する\n",
    "\n",
    "【メモ】\n",
    "* dataset_recover.pyだと\\tが消える\n",
    "    * ピックアップの時点で[SEP]入れるべきでは？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bert_utils import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather(\"input/[DEBUG]dataset_with_original_text/train_with_original_text.feather\")\n",
    "train_duplicated_index = pd.read_json(\"input/[DEBUG]dataset_with_original_text/train_duplicated_index.json\", typ=\"series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "217296it [00:00, 992478.04it/s] \n",
      "1983626it [00:01, 1254455.35it/s]\n",
      "5948218it [00:04, 1369772.10it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_df_list = []\n",
    "for source in [\"newsplus\", \"news4vip\", \"livejupiter\"]:\n",
    "    corpus_df = pd.DataFrame(columns=[\"id\", \"source\", \"text\"])\n",
    "    tsv_line_list = []\n",
    "    with open(input_root+f\"corpus/{source}.tsv\", encoding=\"utf-8\") as f:\n",
    "        for i, l in tqdm(enumerate(f)):\n",
    "            tsv_line_list.append(l)\n",
    "    corpus_df[\"text\"] = tsv_line_list\n",
    "    corpus_df[\"source\"] = source\n",
    "    corpus_df = corpus_df.reset_index(drop=False)\n",
    "    corpus_df[\"id\"] = corpus_df[\"source\"] + \"_\" + corpus_df[\"index\"].astype(str)\n",
    "    corpus_df = corpus_df.drop([\"index\"], axis=1)\n",
    "    corpus_df_list.append(corpus_df)\n",
    "\n",
    "corpus_df = pd.concat(corpus_df_list)\n",
    "corpus_df = corpus_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80074aa43</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>まともに相手されてない人との関係なんて\\nそんな大事にするものか？</td>\n",
       "      <td>0</td>\n",
       "      <td>まともにLINEの返信してくれないんだけど諦めなきゃダメだろ __BR__ フラれたらギクシ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6378fea6b</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>最近はアヘアヘQSマンやない？ ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!</td>\n",
       "      <td>0</td>\n",
       "      <td>柳なんでこんないい時と悪い時の波があるんや\\t最近はアヘアヘQSマンやない？ ｲｲ!(・∀・...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c535f5613</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな</td>\n",
       "      <td>1</td>\n",
       "      <td>日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ __BR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e76638295</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで</td>\n",
       "      <td>0</td>\n",
       "      <td>よくよく思えば川上は配布にしたらとんでもなく有能だよな __BR__ ガチャから引いたら圧倒...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51e4036bf</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...</td>\n",
       "      <td>0</td>\n",
       "      <td>押井は原作レイプの専門家だから __BR__ 原作マンガの真意を誤解させることに関してはプロ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>42b5f86b0</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>車じゃなくてもよくない？\\nケーブル網を張り巡らせてリフトみたいなのを付けるとか</td>\n",
       "      <td>0</td>\n",
       "      <td>車じゃなくてもよくない？ __BR__ ケーブル網を張り巡らせてリフトみたいなのを付けるとか...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>402ce15d9</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>左やぞ？\\n出すなら下水流</td>\n",
       "      <td>0</td>\n",
       "      <td>今からでも野間か松山を出せばいいのに… __BR__ 最近のエルは正直いって期待薄\\t左やぞ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>0739a9fcb</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>日本によって、けんけんガクガクの議論を持たらされた韓国は被害者\\n\\n日本人がしっかり考えな...</td>\n",
       "      <td>0</td>\n",
       "      <td>日本によって、けんけんガクガクの議論を持たらされた韓国は被害者 __BR__ __BR__ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>d496c7dc8</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>ゴムボート買って、沖まで漕いで行ったら？\\n魚の血を塗っておけばサメが食べてくれるよ</td>\n",
       "      <td>0</td>\n",
       "      <td>安楽死を合法にしたら若者殺到するんだろうなあ\\tゴムボート買って、沖まで漕いで行ったら？ _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>d1838f4f0</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>男は美化してないだろ？普通にエロい部分や格好悪い所も描かれてる\\n女の方は主人公美少女しかい...</td>\n",
       "      <td>0</td>\n",
       "      <td>女は女の汚い部分も描きつつ男に理想をもつ __BR__ 男は男を美化しつつ女に理想をもつ\\t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5256 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id       source  \\\n",
       "0     80074aa43     news4vip   \n",
       "1     6378fea6b  livejupiter   \n",
       "2     c535f5613  livejupiter   \n",
       "3     e76638295  livejupiter   \n",
       "4     51e4036bf     newsplus   \n",
       "...         ...          ...   \n",
       "5251  42b5f86b0     news4vip   \n",
       "5252  402ce15d9  livejupiter   \n",
       "5253  0739a9fcb     newsplus   \n",
       "5254  d496c7dc8     news4vip   \n",
       "5255  d1838f4f0     news4vip   \n",
       "\n",
       "                                                   text  label  \\\n",
       "0                     まともに相手されてない人との関係なんて\\nそんな大事にするものか？      0   \n",
       "1                最近はアヘアヘQSマンやない？ ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!      0   \n",
       "2       日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな      1   \n",
       "3      よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで      0   \n",
       "4     押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...      0   \n",
       "...                                                 ...    ...   \n",
       "5251           車じゃなくてもよくない？\\nケーブル網を張り巡らせてリフトみたいなのを付けるとか      0   \n",
       "5252                                      左やぞ？\\n出すなら下水流      0   \n",
       "5253  日本によって、けんけんガクガクの議論を持たらされた韓国は被害者\\n\\n日本人がしっかり考えな...      0   \n",
       "5254         ゴムボート買って、沖まで漕いで行ったら？\\n魚の血を塗っておけばサメが食べてくれるよ      0   \n",
       "5255  男は美化してないだろ？普通にエロい部分や格好悪い所も描かれてる\\n女の方は主人公美少女しかい...      0   \n",
       "\n",
       "                                          original_text  \n",
       "0     まともにLINEの返信してくれないんだけど諦めなきゃダメだろ __BR__ フラれたらギクシ...  \n",
       "1     柳なんでこんないい時と悪い時の波があるんや\\t最近はアヘアヘQSマンやない？ ｲｲ!(・∀・...  \n",
       "2     日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ __BR...  \n",
       "3     よくよく思えば川上は配布にしたらとんでもなく有能だよな __BR__ ガチャから引いたら圧倒...  \n",
       "4     押井は原作レイプの専門家だから __BR__ 原作マンガの真意を誤解させることに関してはプロ...  \n",
       "...                                                 ...  \n",
       "5251  車じゃなくてもよくない？ __BR__ ケーブル網を張り巡らせてリフトみたいなのを付けるとか...  \n",
       "5252  今からでも野間か松山を出せばいいのに… __BR__ 最近のエルは正直いって期待薄\\t左やぞ...  \n",
       "5253  日本によって、けんけんガクガクの議論を持たらされた韓国は被害者 __BR__ __BR__ ...  \n",
       "5254  安楽死を合法にしたら若者殺到するんだろうなあ\\tゴムボート買って、沖まで漕いで行ったら？ _...  \n",
       "5255  女は女の汚い部分も描きつつ男に理想をもつ __BR__ 男は男を美化しつつ女に理想をもつ\\t...  \n",
       "\n",
       "[5256 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [x for x in corpus_df[\"text\"].values if \"まともに相手されてない人\" in x][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]まともにLINEの返信してくれないんだけど諦めなきゃダメだろ。フラれたらギクシャクするだろ[SEP]まともに相手されてない人との関係なんて。そんな大事にするものか？[SEP]そこそこ仲良いんだよグループでは。'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = tt.replace(\"\\t\", \"[SEP]\").replace(\" __BR__ \", \"。\").replace(\"\\n\", \"。\")\n",
    "ttt = \"[CLS]\"+ttt\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tttt = clean_text(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]まともにLINEの返信してくれないんだけど諦めなきゃダメだろ。フラれたらギクシャクするだろ[SEP]まともに相手されてない人との関係なんて。そんな大事にするものか？[SEP]そこそこ仲良いんだよグループでは。'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttttt = juman_parse(tttt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非juman系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='cl-tohoku/bert-base-japanese', vocab_size=32000, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = define_tokenizer(\"cl-tohoku/bert-base-japanese\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'まとも',\n",
       " 'に',\n",
       " 'LINE',\n",
       " 'の',\n",
       " '返',\n",
       " '##信',\n",
       " 'し',\n",
       " 'て',\n",
       " 'くれ',\n",
       " 'ない',\n",
       " 'ん',\n",
       " 'だ',\n",
       " 'けど',\n",
       " '諦め',\n",
       " 'なき',\n",
       " '##ゃ',\n",
       " 'ダメ',\n",
       " 'だろ',\n",
       " 'フラ',\n",
       " 'れ',\n",
       " 'たら',\n",
       " 'ギ',\n",
       " '##クシ',\n",
       " '##ャ',\n",
       " '##ク',\n",
       " 'する',\n",
       " 'だろ',\n",
       " '[SEP]',\n",
       " 'まとも',\n",
       " 'に',\n",
       " '相手',\n",
       " 'さ',\n",
       " 'れ',\n",
       " 'て',\n",
       " 'な',\n",
       " 'い',\n",
       " '##人',\n",
       " 'と',\n",
       " 'の',\n",
       " '関係',\n",
       " 'なんて',\n",
       " 'そんな',\n",
       " '大事',\n",
       " 'に',\n",
       " 'する',\n",
       " 'もの',\n",
       " 'か',\n",
       " '?',\n",
       " '[SEP]',\n",
       " 'そこ',\n",
       " '##そ',\n",
       " '##こ',\n",
       " '仲良',\n",
       " '##い',\n",
       " 'ん',\n",
       " 'だ',\n",
       " 'よ',\n",
       " 'グループ',\n",
       " 'で',\n",
       " 'は']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(tttt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### juman系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'まともにLINEの返信してくれないんだけど諦めなきゃダメだろ __BR__ フラれたらギクシャクするだろ\\tまともに相手されてない人との関係なんて __BR__ そんな大事にするものか？\\tそこそこ仲良いんだよグループでは\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* clean_textは\\tを残す設計になってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'まともにLINEの返信してくれないんだけど諦めなきゃダメだろ__BR__フラれたらギクシャクするだろ\\tまともに相手されてない人との関係なんて__BR__そんな大事にするものか?\\tそこそこ仲良いんだよグループでは'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = clean_text(t)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLSまともにLINEの返信してくれないんだけど諦めなきゃダメだろフラれたらギクシャクするだろSEPまともに相手されてない人との関係なんてそんな大事にするものか?SEPそこそこ仲良いんだよグループでは'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = tt.replace(\"__BR__\", \"\").replace(\"\\t\", \"SEP\")\n",
    "ttt = \"CLS\" + ttt\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLS まともに LINE の 返信 して くれ ない んだ けど 諦め なきゃ ダメだろ フラれたら ギクシャク する だろ SEP まともに 相手 さ れて ない 人 と の 関係 なんて そんな 大事に する もの か ? SEP そこそこ 仲 良い んだ よ グループ で は'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tttt = juman_parse(ttt)\n",
    "tttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] まともに LINE の 返信 して くれ ない んだ けど 諦め なきゃ ダメだろ フラれたら ギクシャク する だろ [SEP] まともに 相手 さ れて ない 人 と の 関係 なんて そんな 大事に する もの か ? [SEP] そこそこ 仲 良い んだ よ グループ で は'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttttt =tttt.replace(\"SEP\", \"[SEP]\").replace(\"CLS\", \"[CLS]\")\n",
    "ttttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='nlp-waseda/roberta-large-japanese-seq512', vocab_size=32000, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = define_tokenizer(\"nlp-waseda/roberta-large-japanese-seq512\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* jumanのあとにspecial-tokenを入れないとカッコをバチ切りされる\n",
    "    * clean_text -> juman -> insert-special-token -> tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 23108,\n",
       " 333,\n",
       " 13173,\n",
       " 261,\n",
       " 22364,\n",
       " 276,\n",
       " 6496,\n",
       " 304,\n",
       " 4736,\n",
       " 4659,\n",
       " 11795,\n",
       " 29159,\n",
       " 15364,\n",
       " 1015,\n",
       " 1830,\n",
       " 4911,\n",
       " 5172,\n",
       " 364,\n",
       " 3661,\n",
       " 23862,\n",
       " 481,\n",
       " 278,\n",
       " 524,\n",
       " 1830,\n",
       " 275,\n",
       " 3,\n",
       " 23108,\n",
       " 333,\n",
       " 1427,\n",
       " 274,\n",
       " 293,\n",
       " 304,\n",
       " 306,\n",
       " 267,\n",
       " 261,\n",
       " 531,\n",
       " 10667,\n",
       " 3299,\n",
       " 26345,\n",
       " 278,\n",
       " 323,\n",
       " 343,\n",
       " 943,\n",
       " 275,\n",
       " 3,\n",
       " 903,\n",
       " 3537,\n",
       " 1094,\n",
       " 3951,\n",
       " 2385,\n",
       " 4736,\n",
       " 1303,\n",
       " 712,\n",
       " 269,\n",
       " 265]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(ttttt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f007669f58917ef828e563fe3b1481c9ee4c6d5364b91c467fc73ebe5072978b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
