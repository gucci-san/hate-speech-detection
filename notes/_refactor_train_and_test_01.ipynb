{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習中断・再開の実装 --\n",
    "* train, validともにtrain.csv全データを使って、\n",
    "    * 一気に5epoch\n",
    "    * 1epochずつ5epoch <br>\n",
    "    行ったときの結果が一致するかを確認する --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "\n",
      "****** SEED fixed : 42 ******\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AdamW\n",
    "\n",
    "from bert_utils import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path+\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"clean_text\"] = train_df[\"text\"].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = define_tokenizer(\"cl-tohoku/bert-base-japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HateSpeechDataset(train_df, tokenizer=tokenizer, max_length=76, num_classes=2, text_col=\"clean_text\", label_name=\"label\")\n",
    "valid_ds = HateSpeechDataset(train_df, tokenizer=tokenizer, max_length=76, num_classes=2, text_col=\"clean_text\", label_name=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=32, num_workers=2, shuffle=True, pin_memory=True, drop_last=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_ds, batch_size=64, num_workers=2, shuffle=False, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mconcatenate-4\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "model = HateSpeechModel(\"cl-tohoku/bert-base-japanese\", 2, custom_header=\"concatenate-4\", dropout=0.2, n_msd=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** *** NOT implemented *** *** \n",
      "        --> CosineAnnealingLR *** *** \n"
     ]
    }
   ],
   "source": [
    "# Define Optimizer and Scheduler --\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "scheduler = fetch_scheduler(optimizer=optimizer, scheduler=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初期状態から5epoch回す --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU : NVIDIA GeForce RTX 3090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:11<00:00, 14.75it/s, Epoch=1, LR=7.6e-6, Train_Loss=0.22]  \n",
      "100%|██████████| 83/83 [00:05<00:00, 15.42it/s, Epoch=1, LR=7.6e-6, Valid_Loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss Improved : inf ---> 0.122735\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 147/164 [00:09<00:01, 15.32it/s, Epoch=2, LR=3.2e-6, Train_Loss=0.113] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m model, history \u001b[38;5;241m=\u001b[39m run_training(\n\u001b[1;32m      4\u001b[0m     model, train_loader, valid_loader,\n\u001b[1;32m      5\u001b[0m     optimizer, scheduler, \u001b[38;5;241m1\u001b[39m, device,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ALL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./test/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, save_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, load_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/poetry_projects/hate-speech-detection/bert_utils.py:438\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(model, train_loader, valid_loader, optimizer, scheduler, n_accumulate, device, use_amp, num_epochs, fold, output_path, log, save_checkpoint, load_checkpoint)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=434'>435</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epoch, num_epochs\u001b[39m+\u001b[39mstart_epoch):\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=435'>436</a>\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m--> <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=437'>438</a>\u001b[0m     train_epoch_loss \u001b[39m=\u001b[39m train_one_epoch(\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=438'>439</a>\u001b[0m         model, optimizer, scheduler,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=439'>440</a>\u001b[0m         dataloader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=440'>441</a>\u001b[0m         device\u001b[39m=\u001b[39;49mdevice, use_amp\u001b[39m=\u001b[39;49muse_amp, epoch\u001b[39m=\u001b[39;49mepoch,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=441'>442</a>\u001b[0m         n_accumulate\u001b[39m=\u001b[39;49mn_accumulate\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=442'>443</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=444'>445</a>\u001b[0m     valid_epoch_loss \u001b[39m=\u001b[39m valid_one_epoch(\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=445'>446</a>\u001b[0m         model, optimizer, \n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=446'>447</a>\u001b[0m         dataloader\u001b[39m=\u001b[39mvalid_loader,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=447'>448</a>\u001b[0m         device\u001b[39m=\u001b[39mdevice, epoch\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=448'>449</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=450'>451</a>\u001b[0m     history[\u001b[39m\"\u001b[39m\u001b[39mTrain Loss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(train_epoch_loss)\n",
      "File \u001b[0;32m~/poetry_projects/hate-speech-detection/bert_utils.py:359\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, use_amp, epoch, n_accumulate)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=356'>357</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=357'>358</a>\u001b[0m loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mfloat(n_accumulate)\n\u001b[0;32m--> <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=358'>359</a>\u001b[0m scaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=360'>361</a>\u001b[0m \u001b[39mif\u001b[39;00m (step\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m n_accumulate \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/bert_utils.py?line=361'>362</a>\u001b[0m     scaler\u001b[39m.\u001b[39mstep(optimizer)\n",
      "File \u001b[0;32m~/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/_tensor.py?line=386'>387</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/_tensor.py?line=387'>388</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/_tensor.py?line=388'>389</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/_tensor.py?line=389'>390</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/_tensor.py?line=393'>394</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/_tensor.py?line=394'>395</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/_tensor.py?line=395'>396</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "model, history = run_training(\n",
    "    model, train_loader, valid_loader,\n",
    "    optimizer, scheduler, 1, device,\n",
    "    True, 5, \"_ALL\", \"./test/\",\n",
    "    log=None, save_checkpoint=True, load_checkpoint=None\n",
    ") # -> \"./test/checkpoint-fold_ALL.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f007669f58917ef828e563fe3b1481c9ee4c6d5364b91c467fc73ebe5072978b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
