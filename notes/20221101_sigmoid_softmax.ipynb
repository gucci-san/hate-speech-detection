{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorchのsigmoidとsoftmaxについてハマったのでメモ --\n",
    "【対応】\n",
    "* BCEwithLogitLoss(outputs, targets) = BCELoss(sigmoid(outputs), targets)\n",
    "* CrossEntropyLoss(outputs, targets) = NLLLoss(softmax(outputs), targets)\n",
    "\n",
    "さらに、targetsの形について\n",
    "* BCE, NLL : targets.shape = [num_classes, 1], 値がカテゴリ名\n",
    "    * つまり、 torch.argmax(targets, axis=1)\n",
    "\n",
    "* CrossEntropyLossはなぜかどっちでもよい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 適当な結果を読み込む --\n",
    "train_df = pd.read_feather(\"output/roberta_large_cat4/train_df.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0, logits = (確率化される前のNNのアウトプット)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.3130, -5.3238],\n",
       "        [ 5.9247, -5.9556],\n",
       "        [-0.9774,  0.9705],\n",
       "        ...,\n",
       "        [ 3.4022, -3.0494],\n",
       "        [ 5.8692, -5.8984],\n",
       "        [ 5.2150, -5.3340]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.Tensor(train_df.loc[:, [\"model_oof_class_0\", \"model_oof_class_1\"]].values)\n",
    "tt # logits --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1, sigmoidとsoftmaxは別物 --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9951, 0.0049],\n",
       "        [0.9973, 0.0026],\n",
       "        [0.2734, 0.7252],\n",
       "        ...,\n",
       "        [0.9678, 0.0452],\n",
       "        [0.9972, 0.0027],\n",
       "        [0.9946, 0.0048]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sigmoidは厳密な確率空間への変換になっていない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9999, 0.9999, 0.9986,  ..., 1.0130, 0.9999, 0.9994])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(tt).sum(axis=1) # 1にならない --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(tt).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2, BCELossとBCELossWithLogitsLoss --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.Tensor([\n",
    "    [1e6, 1e-6],\n",
    "    [1e6, 1e-6],\n",
    "    [1e6, 1e-6]\n",
    "])\n",
    "\n",
    "targets = torch.Tensor([\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [1, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BCELossはoutputs, targetsともにprobaを受け取る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.0132)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bceloss = nn.BCELoss()\n",
    "bceloss(sigmoid(outputs), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33.3333)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bceloss(softmax(outputs), targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BCELosswithLogitslossはlogitsを受け取れる --\n",
    "    * ここで、0.7561で一致することから「BCEwithLogitsLossは内部でSigmoidを適用している」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(166667.0156)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcelossw = nn.BCEWithLogitsLoss()\n",
    "bcelossw(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Softmaxを適用してるのはnn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(333333.3438)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closs = nn.CrossEntropyLoss()\n",
    "closs(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_argmax = torch.argmax(targets, axis=1)\n",
    "targets_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(333333.3438)\n"
     ]
    }
   ],
   "source": [
    "print(closs(outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(333333.3438)\n"
     ]
    }
   ],
   "source": [
    "print(closs(outputs, targets_argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* さらに、CELはこれと一緒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllloss = nn.NLLLoss(weight=torch.Tensor([100, 0]))\n",
    "logsoftmax = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[       0., -1000000.],\n",
      "        [       0., -1000000.],\n",
      "        [       0., -1000000.]])\n",
      "tensor([0, 1, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(logsoftmax(outputs))\n",
    "print(torch.argmax(targets, axis=1))\n",
    "\n",
    "nllloss(\n",
    "    logsoftmax(outputs),\n",
    "    torch.argmax(targets, axis=1)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f007669f58917ef828e563fe3b1481c9ee4c6d5364b91c467fc73ebe5072978b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
