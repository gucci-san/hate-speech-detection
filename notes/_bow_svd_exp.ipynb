{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf->TruncatedSVDの実験をするnotebook\n",
    "\n",
    "* SVDとPCAは大体同じ、数値的にはSVDのほうが安定\n",
    "    * https://qiita.com/horiem/items/71380db4b659fb9307b4\n",
    "\n",
    "* n_iterは（このデータ数なら）二桁で十分そう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "\n",
      "****** SEED fixed : 42 ******\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import MeCab\n",
    "import re\n",
    "from config import *\n",
    "from bert_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wakati_clear(text):\n",
    "    text = re.sub(r'、', '', text)\n",
    "    text = re.sub(r'。', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def wakatier(text, tagger=MeCab.Tagger(f\"-Owakati -d {dic_neologd}\")):\n",
    "    return wakati_clear(tagger.parse(text))\n",
    "\n",
    "\n",
    "def calc_tfidf(text_list: list) -> pd.DataFrame:\n",
    "    bow = CountVectorizer()\n",
    "    tfidf = TfidfTransformer(smooth_idf=False)\n",
    "\n",
    "    count = bow.fit_transform(text_list)\n",
    "    array_bow = count.toarray() # BoW: 出現回数[dim] --\n",
    "    # cf.) array_tf = array_bow / array_bow.shape[1]  # 出現確率[undim]... terms frequency, tf --\n",
    "    df_tfidf = pd.DataFrame(tfidf.fit_transform(array_bow).toarray(), columns=bow.get_feature_names_out())\n",
    "    df_bow = pd.DataFrame(array_bow, columns=bow.get_feature_names_out())\n",
    "    return df_tfidf, df_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果のdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.DataFrame(columns=[\"sample\", \"cols\", \"n_components\", \"n_iter\", \"explained_variance_ratio_sum\", \"time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_components, n_iterに対してexplained_variance_ratio_の収束性 --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance_ratio_.sum() 0.002804907417058345\n",
      "explained_variance_ratio_.sum() 0.0027693729455987855\n",
      "explained_variance_ratio_.sum() 0.18485468039329048\n",
      "explained_variance_ratio_.sum() 0.220501545715091\n",
      "explained_variance_ratio_.sum() 0.40159570679723067\n",
      "explained_variance_ratio_.sum() 0.4521029488056133\n",
      "explained_variance_ratio_.sum() 0.7881391364120922\n",
      "explained_variance_ratio_.sum() 0.8251719661805887\n",
      "explained_variance_ratio_.sum() 0.923687497348773\n",
      "explained_variance_ratio_.sum() 0.9426668097065459\n"
     ]
    }
   ],
   "source": [
    "svd_components = 256\n",
    "\n",
    "singular_values = []\n",
    "explained_variance_ratio = []\n",
    "for svd_components in [1, 256, 1024, 4096, 6144]:\n",
    "    for n_iter in [1, 32]:\n",
    "    \n",
    "        start_time = time.time()\n",
    "    \n",
    "        # prepare data --\n",
    "        df, train_shape = prepare_dataframe(train_data=\"raw\")\n",
    "        df[\"clean_text\"] = df[\"text\"].map(lambda x: clean_text(x))\n",
    "        text_list = df[\"clean_text\"].values\n",
    "        for i in range(len(text_list)):\n",
    "            text_list[i] = wakatier(text_list[i])\n",
    "        \n",
    "        # tfidf -> SVD --\n",
    "        df_tfidf, df_bow = calc_tfidf(text_list)\n",
    "        df_tfidf_sparse = csr_matrix(df_tfidf)\n",
    "        svd = TruncatedSVD(n_components=svd_components, n_iter=n_iter, random_state=SEED)\n",
    "        df_tfidf_svd = pd.DataFrame(svd.fit_transform(df_tfidf_sparse), columns=[f\"svd_{str(i)}\" for i in range(svd_components)])\n",
    "    \n",
    "        singular_values.append(svd.singular_values_)\n",
    "        explained_variance_ratio.append(svd.explained_variance_ratio_)\n",
    "    \n",
    "        print(\"explained_variance_ratio_.sum()\", svd.explained_variance_ratio_.sum())\n",
    "    \n",
    "        end_time = time.time()\n",
    "        time_elapsed = end_time - start_time\n",
    "        time_elapsed_str = \"{:.0f}h {:.0f}m {:.0f}s\".format(time_elapsed//3600, (time_elapsed%3600)//60, (time_elapsed%3600)%60)\n",
    "    \n",
    "        # save exp result --\n",
    "        log_df = pd.concat([log_df, pd.DataFrame(pd.Series({\n",
    "            \"sample\": df_bow.shape[0],\n",
    "            \"cols\": df_bow.shape[1],\n",
    "            \"n_components\": svd_components,\n",
    "            \"n_iter\": n_iter,\n",
    "            \"explained_variance_ratio_sum\": svd.explained_variance_ratio_.sum(),\n",
    "            \"time\": time_elapsed_str,\n",
    "        })).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.to_csv(\"./experiment/train_test_bow_svd_experiment.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f007669f58917ef828e563fe3b1481c9ee4c6d5364b91c467fc73ebe5072978b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
