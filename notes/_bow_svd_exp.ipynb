{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf->TruncatedSVDの実験をするnotebook\n",
    "\n",
    "* SVDとPCAは大体同じ、数値的にはSVDのほうが安定\n",
    "    * https://qiita.com/horiem/items/71380db4b659fb9307b4\n",
    "\n",
    "* n_iterは（このデータ数なら）二桁で十分そう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "\n",
      "****** SEED fixed : 42 ******\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import MeCab\n",
    "import re\n",
    "from config import *\n",
    "from bert_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wakati_clear(text):\n",
    "    text = re.sub(r'、', '', text)\n",
    "    text = re.sub(r'。', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def wakatier(text, tagger=MeCab.Tagger(f\"-Owakati -d {dic_neologd}\")):\n",
    "    return wakati_clear(tagger.parse(text))\n",
    "\n",
    "\n",
    "def calc_tfidf(text_list: list) -> pd.DataFrame:\n",
    "    bow = CountVectorizer()\n",
    "    tfidf = TfidfTransformer(smooth_idf=False)\n",
    "\n",
    "    count = bow.fit_transform(text_list)\n",
    "    array_bow = count.toarray() # BoW: 出現回数[dim] --\n",
    "    # cf.) array_tf = array_bow / array_bow.shape[1]  # 出現確率[undim]... terms frequency, tf --\n",
    "    df_tfidf = pd.DataFrame(tfidf.fit_transform(array_bow).toarray(), columns=bow.get_feature_names_out())\n",
    "    df_bow = pd.DataFrame(array_bow, columns=bow.get_feature_names_out())\n",
    "    return df_tfidf, df_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果のdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.DataFrame(columns=[\"sample\", \"cols\", \"n_components\", \"n_iter\", \"explained_variance_ratio_sum\", \"time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_components, n_iterに対してexplained_variance_ratio_の収束性 --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance_ratio_.sum() 0.002804907417058345\n",
      "explained_variance_ratio_.sum() 0.0027693729455987855\n",
      "explained_variance_ratio_.sum() 0.18485468039329048\n",
      "explained_variance_ratio_.sum() 0.220501545715091\n",
      "explained_variance_ratio_.sum() 0.40159570679723067\n",
      "explained_variance_ratio_.sum() 0.4521029488056133\n",
      "explained_variance_ratio_.sum() 0.7881391364120922\n",
      "explained_variance_ratio_.sum() 0.8251719661805887\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (8479, 8479), indices imply (8479, 10240)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m df_tfidf_sparse \u001b[38;5;241m=\u001b[39m csr_matrix(df_tfidf)\n\u001b[1;32m     20\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39msvd_components, n_iter\u001b[38;5;241m=\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39mSEED)\n\u001b[0;32m---> 21\u001b[0m df_tfidf_svd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(svd\u001b[38;5;241m.\u001b[39mfit_transform(df_tfidf_sparse), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(svd_components)])\n\u001b[1;32m     23\u001b[0m singular_values\u001b[38;5;241m.\u001b[39mappend(svd\u001b[38;5;241m.\u001b[39msingular_values_)\n\u001b[1;32m     24\u001b[0m explained_variance_ratio\u001b[38;5;241m.\u001b[39mappend(svd\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_)\n",
      "File \u001b[0;32m~/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=710'>711</a>\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=711'>712</a>\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=712'>713</a>\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=717'>718</a>\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=718'>719</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=719'>720</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=720'>721</a>\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=721'>722</a>\u001b[0m             data,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=722'>723</a>\u001b[0m             index,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=723'>724</a>\u001b[0m             columns,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=724'>725</a>\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=725'>726</a>\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=726'>727</a>\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=727'>728</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=729'>730</a>\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=730'>731</a>\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py:350\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=344'>345</a>\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=345'>346</a>\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=346'>347</a>\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=347'>348</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=349'>350</a>\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=351'>352</a>\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=353'>354</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py:421\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=418'>419</a>\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=419'>420</a>\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> <a href='file:///home/marimo/poetry_projects/hate-speech-detection/.venv/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=420'>421</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (8479, 8479), indices imply (8479, 10240)"
     ]
    }
   ],
   "source": [
    "svd_components = 256\n",
    "\n",
    "singular_values = []\n",
    "explained_variance_ratio = []\n",
    "for svd_components in [1, 256, 1024, 4096, 6144]:\n",
    "    for n_iter in [1, 32]:\n",
    "    \n",
    "        start_time = time.time()\n",
    "    \n",
    "        # prepare data --\n",
    "        df, train_shape = prepare_dataframe(train_data=\"raw\")\n",
    "        df[\"clean_text\"] = df[\"text\"].map(lambda x: clean_text(x))\n",
    "        text_list = df[\"clean_text\"].values\n",
    "        for i in range(len(text_list)):\n",
    "            text_list[i] = wakatier(text_list[i])\n",
    "        \n",
    "        # tfidf -> SVD --\n",
    "        df_tfidf, df_bow = calc_tfidf(text_list)\n",
    "        df_tfidf_sparse = csr_matrix(df_tfidf)\n",
    "        svd = TruncatedSVD(n_components=svd_components, n_iter=n_iter, random_state=SEED)\n",
    "        df_tfidf_svd = pd.DataFrame(svd.fit_transform(df_tfidf_sparse), columns=[f\"svd_{str(i)}\" for i in range(svd_components)])\n",
    "    \n",
    "        singular_values.append(svd.singular_values_)\n",
    "        explained_variance_ratio.append(svd.explained_variance_ratio_)\n",
    "    \n",
    "        print(\"explained_variance_ratio_.sum()\", svd.explained_variance_ratio_.sum())\n",
    "    \n",
    "        end_time = time.time()\n",
    "        time_elapsed = end_time - start_time\n",
    "        time_elapsed_str = \"{:.0f}h {:.0f}m {:.0f}s\".format(time_elapsed//3600, (time_elapsed%3600)//60, (time_elapsed%3600)%60)\n",
    "    \n",
    "        # save exp result --\n",
    "        log_df = pd.concat([log_df, pd.DataFrame(pd.Series({\n",
    "            \"sample\": df_bow.shape[0],\n",
    "            \"cols\": df_bow.shape[1],\n",
    "            \"n_components\": svd_components,\n",
    "            \"n_iter\": n_iter,\n",
    "            \"explained_variance_ratio_sum\": svd.explained_variance_ratio_.sum(),\n",
    "            \"time\": time_elapsed_str,\n",
    "        })).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.to_csv(\"./experiment/train_test_bow_svd_experiment.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f007669f58917ef828e563fe3b1481c9ee4c6d5364b91c467fc73ebe5072978b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
