{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTでベースラインを組む(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** SEED fixed : 42 ******\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import gc, os, random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertJapaneseTokenizer, BertForSequenceClassification, \n",
    "    AutoTokenizer, AutoModel, AutoModelForSequenceClassification, \n",
    "    Trainer, TrainingArguments, EvalPrediction, AdamW\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from config import *\n",
    "from myutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predを作りたいrun_idのフォルダパスを指定 --\n",
    "# スクリプト化すれば悩むこともないかもだけど、notebook分けて実行するときは読み込み先が一意に定まらないと気持ち悪い --\n",
    "# => configを全部notebook内で書いて逆にjsonに吐くとかすれば行けそう --\n",
    "\n",
    "# そもそもそれやるより、baselineのコードをpy化したほうが良くないか？後々使えるし...\n",
    "run_id = \"tmp\"\n",
    "output_path = f\"./output/{run_id}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "folds = 5\n",
    "model_name = r\"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
    "train_batch_size = 32\n",
    "valid_batch_size = 64\n",
    "test_batch_size = 64\n",
    "max_length = 76\n",
    "\n",
    "learning_rate = 1e-6\n",
    "scheduler_name = \"CosineAnnealingLR\"\n",
    "min_lr = 1e-7\n",
    "T_max = 500,\n",
    "weight_decay = 1e-6\n",
    "max_grad_norm = 1.0\n",
    "n_accumulate = 1\n",
    "num_classes = 2\n",
    "n_fold = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hidden_size = 768\n",
    "num_hidden_layers = 24\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = glob(f\"{output_path}*.pth\"); model_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./output/tmp/model-fold0.pth']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_feather(f\"{output_path}test_df.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
    "    mecab_kwargs={\"mecab_dic\":None, \"mecab_option\": f\"-d {dic_neologd}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length, num_classes, text_col=\"text\", isTrain=True):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = df[text_col].values\n",
    "        self.num_classes = num_classes\n",
    "        if isTrain:\n",
    "            self.target = df[label_name].values\n",
    "        else:\n",
    "            self.target = np.zeros(df.shape[0])\n",
    "        self.isTrain = isTrain\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        text = self.text[index]\n",
    "        inputs_text = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        if self.isTrain:\n",
    "            target = int(self.target[index])\n",
    "            onehot_t = np.zeros(self.num_classes, dtype=np.float32)\n",
    "            onehot_t[target] = 1.0\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(inputs_text[\"input_ids\"], dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(inputs_text[\"attention_mask\"], dtype=torch.long),\n",
    "                \"target\": torch.tensor(onehot_t, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(inputs_text[\"input_ids\"], dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(inputs_text[\"attention_mask\"], dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateSpeechModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super(HateSpeechModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True,\n",
    "            )\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=False)\n",
    "        out = self.dropout(out[1])\n",
    "        outputs = self.fc(out)\n",
    "        outputs = self.sigmoid(outputs)\n",
    "\n",
    "        return outputs.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_fn(model, dataloader, device):\n",
    "    model.eval()  # modelはtrainの時点でto(device)されている前提 --\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        input_ids = data[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        attention_mask = data[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "\n",
    "        preds.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    gc.collect()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model_name, num_classes, model_paths, dataloader, device):\n",
    "    final_preds = []\n",
    "\n",
    "    for i, path in enumerate([model_paths]):\n",
    "        model = HateSpeechModel(model_name=model_name, num_classes=num_classes)\n",
    "        model.to(device)\n",
    "        checkpoint = torch.load(model_paths)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        print(f\"Getting predictions for model {i+1}\")\n",
    "        preds = valid_fn(model, dataloader, device)\n",
    "        final_preds.append(preds)\n",
    "\n",
    "\n",
    "    final_preds = np.array(final_preds)\n",
    "    final_preds = np.mean(final_preds, axis=0)\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = HateSpeechDataset(test_df, tokenizer=tokenizer, max_length=max_length, num_classes=num_classes, text_col=\"clean_text\", isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, num_workers=2, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:03<00:00, 12.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for fold in range(0, folds):\n",
    "    preds = inference(model_name, num_classes, model_paths[fold], test_loader, device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81462973, 0.18600619],\n",
       "       [0.72755533, 0.20633605],\n",
       "       [0.8023047 , 0.19576396],\n",
       "       ...,\n",
       "       [0.8148778 , 0.19981457],\n",
       "       [0.8307979 , 0.18185726],\n",
       "       [0.82658386, 0.19169123]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"oof\"] = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5256</td>\n",
       "      <td>001026808</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>上でも言ったけどオタクレベルの知識求めてる訳じゃない\\nただ囲碁やります！って人が誰1人プロ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>上でも言ったけどオタクレベルの知識求めてる訳じゃないただ囲碁やります!って人が誰1人プロ棋士...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5257</td>\n",
       "      <td>00465ac96</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>たとえば、黒人なんかは、生物学的欠陥はないのに、文化的要因で、悪循環に陥り、実力をつけられず...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>たとえば黒人なんかは生物学的欠陥はないのに文化的要因で悪循環に陥り実力をつけられずに生きてき...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5258</td>\n",
       "      <td>004674725</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>そうなんやろなあ色々と勿体ない感じしたわ\\n終わり方と黒幕キャラは好きやったで\\n\\nちなワ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>そうなんやろなあ色と勿体ない感じしたわ終わり方と黒幕キャラは好きやったでちなワイはダークナイ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5259</td>\n",
       "      <td>00474460f</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>法的というか自治体ごとにバラバラの条例で定めてるだけだからな\\n普通の淫行条例だと「青少年に...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>法的というか自治体ごとにバラバラの条例で定めてるだけだからな普通の淫行条例だと青少年に淫らな...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5260</td>\n",
       "      <td>004a7525c</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど、\\n現地は不測の事...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど現地は不測の事態が起...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>8474</td>\n",
       "      <td>ffc4647ac</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>１人がいいのか？\\nなんで変なのと同棲したのか…\\nなにがしたいんだ…</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1人がいいのか?なんで変なのと同棲したのか…なにがしたいんだ…</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>8475</td>\n",
       "      <td>ffc6554ba</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>ロシアもだなあ\\n元々北朝鮮はロシアの工作で作られた国だから</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ロシアもだなあ元北朝鮮はロシアの工作で作られた国だから</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>8476</td>\n",
       "      <td>ffd3b29c2</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>クネが国境に拡声器を設置して昼も夜も北の悪口鳴らしてんだとよ\\nお互い当たらないように大砲撃...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>クネが国境に拡声器を設置して昼も夜も北の悪口鳴らしてんだとよお互い当たらないように大砲撃ち合...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>8477</td>\n",
       "      <td>ffd3c69b6</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>当然って言い方が腹立つんだよなあ\\r\\nその時点で何か男より優位に立ちたいみたいな感じがして...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>当然って言い方が腹立つんだよなあその時点で何か男より優位に立ちたいみたいな感じがしてくるんだ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>8478</td>\n",
       "      <td>fff5802e5</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>議員辞職したわけじゃないから、無所属でどこかの会派に入ればいいだけなんじゃないの？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>議員辞職したわけじゃないから無所属でどこかの会派に入ればいいだけなんじゃないの?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3223 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         id       source  \\\n",
       "0      5256  001026808     news4vip   \n",
       "1      5257  00465ac96  livejupiter   \n",
       "2      5258  004674725  livejupiter   \n",
       "3      5259  00474460f     news4vip   \n",
       "4      5260  004a7525c     newsplus   \n",
       "...     ...        ...          ...   \n",
       "3218   8474  ffc4647ac     news4vip   \n",
       "3219   8475  ffc6554ba     newsplus   \n",
       "3220   8476  ffd3b29c2     newsplus   \n",
       "3221   8477  ffd3c69b6     news4vip   \n",
       "3222   8478  fff5802e5     newsplus   \n",
       "\n",
       "                                                   text  label  \\\n",
       "0     上でも言ったけどオタクレベルの知識求めてる訳じゃない\\nただ囲碁やります！って人が誰1人プロ...    NaN   \n",
       "1     たとえば、黒人なんかは、生物学的欠陥はないのに、文化的要因で、悪循環に陥り、実力をつけられず...    NaN   \n",
       "2     そうなんやろなあ色々と勿体ない感じしたわ\\n終わり方と黒幕キャラは好きやったで\\n\\nちなワ...    NaN   \n",
       "3     法的というか自治体ごとにバラバラの条例で定めてるだけだからな\\n普通の淫行条例だと「青少年に...    NaN   \n",
       "4     別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど、\\n現地は不測の事...    NaN   \n",
       "...                                                 ...    ...   \n",
       "3218                １人がいいのか？\\nなんで変なのと同棲したのか…\\nなにがしたいんだ…    NaN   \n",
       "3219                     ロシアもだなあ\\n元々北朝鮮はロシアの工作で作られた国だから    NaN   \n",
       "3220  クネが国境に拡声器を設置して昼も夜も北の悪口鳴らしてんだとよ\\nお互い当たらないように大砲撃...    NaN   \n",
       "3221  当然って言い方が腹立つんだよなあ\\r\\nその時点で何か男より優位に立ちたいみたいな感じがして...    NaN   \n",
       "3222          議員辞職したわけじゃないから、無所属でどこかの会派に入ればいいだけなんじゃないの？    NaN   \n",
       "\n",
       "                                             clean_text  oof  \n",
       "0     上でも言ったけどオタクレベルの知識求めてる訳じゃないただ囲碁やります!って人が誰1人プロ棋士...    0  \n",
       "1     たとえば黒人なんかは生物学的欠陥はないのに文化的要因で悪循環に陥り実力をつけられずに生きてき...    0  \n",
       "2     そうなんやろなあ色と勿体ない感じしたわ終わり方と黒幕キャラは好きやったでちなワイはダークナイ...    0  \n",
       "3     法的というか自治体ごとにバラバラの条例で定めてるだけだからな普通の淫行条例だと青少年に淫らな...    0  \n",
       "4     別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど現地は不測の事態が起...    0  \n",
       "...                                                 ...  ...  \n",
       "3218                    1人がいいのか?なんで変なのと同棲したのか…なにがしたいんだ…    0  \n",
       "3219                        ロシアもだなあ元北朝鮮はロシアの工作で作られた国だから    0  \n",
       "3220  クネが国境に拡声器を設置して昼も夜も北の悪口鳴らしてんだとよお互い当たらないように大砲撃ち合...    0  \n",
       "3221  当然って言い方が腹立つんだよなあその時点で何か男より優位に立ちたいみたいな感じがしてくるんだ...    0  \n",
       "3222           議員辞職したわけじゃないから無所属でどこかの会派に入ればいいだけなんじゃないの?    0  \n",
       "\n",
       "[3223 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f\"{data_path}sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(submission, test_df.loc[:, [\"id\", \"oof\"]], how=\"left\", on=\"id\").drop([\"label\"], axis=1).rename(columns={\"oof\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f\"{output_path}submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f007669f58917ef828e563fe3b1481c9ee4c6d5364b91c467fc73ebe5072978b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
