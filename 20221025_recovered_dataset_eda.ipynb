{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10/26時点のrecover-original-textのイケ具合を確認しつつ、テキストの抜粋基準について検討する\n",
    "* まずイケてないです\n",
    "* 「ああああああ」「ﾌﾞﾘｭﾌﾞﾘｭ」「ええんやで」「クレメンス」的なミームが入ってるやつはたくさんヒットしてしまう\n",
    "    * とりあえず意味変わってなさそうやしいいんじゃね？\n",
    "* 顔文字のバリエーションが多すぎて突破困難\n",
    "    * とりあえずjuman通るようにreplaceして、他は無視"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather(\"input/dataset_with_original_text/train_with_original_text.feather\")\n",
    "test_df = pd.read_feather(\"input/dataset_with_original_text/test_with_original_text.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "\n",
      "****** SEED fixed : 256 ******\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bert_utils import *\n",
    "train_df[\"clean_text\"] = train_df[\"original_text\"].map(lambda x: original_text_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk1 = define_tokenizer(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
    "tk2 = define_tokenizer(\"nlp-waseda/roberta-large-japanese-seq512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb565280440a465cbde6b803de293585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=657), Label(value='0 / 657'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ~3sec --\n",
    "train_df[\"clean_text1\"] = train_df[\"original_text\"].parallel_map(lambda x: original_text_preprocess(x, use_juman=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440d96b1f3bc41cca924954d7f4945f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=657), Label(value='0 / 657'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"clean_text2\"] = train_df[\"original_text\"].parallel_map(lambda x: original_text_preprocess(x, use_juman=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークン数に関する検討 --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非Juman系 ]333 --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506       7\n",
       "2615     12\n",
       "1976     15\n",
       "1265     15\n",
       "2661     17\n",
       "       ... \n",
       "2811    271\n",
       "3297    275\n",
       "4400    284\n",
       "2853    319\n",
       "4989    333\n",
       "Name: clean_text1, Length: 5256, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"clean_text1\"].map(lambda x: len(tk1.tokenize(x))).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juman系 :346 --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506       8\n",
       "2615     13\n",
       "1265     14\n",
       "2902     16\n",
       "1976     18\n",
       "       ... \n",
       "4400    267\n",
       "4067    279\n",
       "3297    284\n",
       "2853    315\n",
       "4989    346\n",
       "Name: clean_text2, Length: 5256, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"clean_text2\"].map(lambda x: len(tk2.tokenize(x))).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 23135, 7, 21117, 5, 2434, 28836, 15, 16, 4831, 80, 1058, 75, 11218, 14209, 9968, 29360, 20856, 3635, 2889, 20, 3318, 708, 14143, 28563, 28488, 34, 3635, 3, 23135, 7, 1879, 26, 20, 16, 18, 21, 28514, 13, 5, 633, 15060, 4799, 15872, 7, 34, 120, 29, 2935, 3, 1221, 28516, 28482, 20663, 28457, 1058, 75, 54, 1091, 12, 9, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk1.encode_plus(\n",
    "    train_df[\"clean_text1\"][0],\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4800, train_df.shape[0]):\n",
    "#     print(i)\n",
    "#     t = original_text_preprocess(train_df.loc[i, \"original_text\"], use_juman=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### juman_parseで引っかかったやつ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ネトウヨってバカだなぁ韓国側が反日運動する時は散叩くクセに自分たちはヘイトスピーチ禁止されて怒り狂ってるんだwwwお前らの言ってる事って結局のところ反日やってる韓国人と全く変わんないって事に気づいた方がいいよ [SEP]日本人に対するヘイトは含まないって言ってるのも理解できないとは本当に日本人じゃないんだろうな[SEP]じゃあお前日本人に対するヘイトスピーチ見た事あんのかよ俺は今まで韓国や中国に対するものしか見た事ねーぞ[SEP]さすが地震をお祝いして国旗を平気に燃やす(日本では犯罪)民族は言うことが違うな'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[3218, \"clean_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'志位るず界隈しばき隊界隈はこれからパヨクっていわれちゃうの?wwwwww[SEP]>パヨクそれいただきましたw[SEP]相変わらずこういうときの真紅ってキレッキレやと思うねんwwww'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = train_df.loc[3239, \"clean_text\"]\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'おやおや、移民難民は受け入れろだの救えだのおっしゃる上級国民様はダンマリかいｗ\\tその上級国民って誰？\\t○ニクロのしゃっちょさんとかアカヒなどのマスゴミ様とか\\tそっか __BR__ ありがとう<(_ _)>\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = train_df.loc[4102, \"original_text\"]\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bcxx氏のアカが消えていたのですが、何かあったんですかね？(名の有るパヨクの何人かも11/14～11/15以降はパヨった書き込み無しで、リツイートぐらい、確認出来た所だと、パヨって暴れているのは在日韓国人の人達ばかり)\\t竹内のツイアカは消えてないぞ __BR__ いくつかの書き込みを消しただけじゃないかな\\tそうなんですね __BR__ もう一度探してみます __BR__ 有難うございました __BR__ m(_ _)m\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = train_df.loc[4871, \"original_text\"]\n",
    "tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 顔文字チェックはtestでもやっておく --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, test_df.shape[0]):\n",
    "#     print(i)\n",
    "#     t = original_text_preprocess(test_df.loc[i, \"original_text\"], use_juman=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理が思った動きしてなくない？ --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3点リーダが消えない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5MRはどうしてわたしの指摘スルーしたの？ｗ __BR__ なのにどうしてガンガン自分の意見だしてるの？ｗ __BR__ どの面さげてｗ\\tお前に興味ないからかな\\tはいにげたっとｗ __BR__ 一発でつぶれてたのかｗ __BR__ あれだけ勇んでたのにｗｗｗ __BR__ スルーした君はひとに意見求める資格なーっしｗ\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[180, \"original_text\"].replace(\"…\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>まともにLINEの返信してくれないんだけど諦めなきゃダメだろフラれたらギクシャクするだろ[S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>柳なんでこんないい時と悪い時の波があるんや[SEP]最近はアヘアヘQSマンやない? イイ!(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ甘えるな[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>よくよく思えば川上は配布にしたらとんでもなく有能だよなガチャから引いたら圧倒的歓喜レベルやで...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>押井は原作レイプの専門家だから原作マンガの真意を誤解させることに関してはプロだがそれ以外には...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>0</td>\n",
       "      <td>車じゃなくてもよくない?ケーブル網を張り巡らせてリフトみたいなのを付けるとか[SEP]それな...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>0</td>\n",
       "      <td>今からでも野間か松山を出せばいいのに最近のエルは正直いって期待薄[SEP]左やぞ?出すなら下...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>0</td>\n",
       "      <td>日本によってけんけんガクガクの議論を持たらされた韓国は被害者日本人がしっかり考えないと10億...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>0</td>\n",
       "      <td>安楽死を合法にしたら若者殺到するんだろうなあ[SEP]ゴムボート買って沖まで漕いで行ったら?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>0</td>\n",
       "      <td>女は女の汚い部分も描きつつ男に理想をもつ男は男を美化しつつ女に理想をもつ[SEP]男は美化し...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                         clean_text\n",
       "0         0  まともにLINEの返信してくれないんだけど諦めなきゃダメだろフラれたらギクシャクするだろ[S...\n",
       "1         0  柳なんでこんないい時と悪い時の波があるんや[SEP]最近はアヘアヘQSマンやない? イイ!(...\n",
       "2         1  日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ甘えるな[...\n",
       "3         0  よくよく思えば川上は配布にしたらとんでもなく有能だよなガチャから引いたら圧倒的歓喜レベルやで...\n",
       "4         0  押井は原作レイプの専門家だから原作マンガの真意を誤解させることに関してはプロだがそれ以外には...\n",
       "...     ...                                                ...\n",
       "5251      0  車じゃなくてもよくない?ケーブル網を張り巡らせてリフトみたいなのを付けるとか[SEP]それな...\n",
       "5252      0  今からでも野間か松山を出せばいいのに最近のエルは正直いって期待薄[SEP]左やぞ?出すなら下...\n",
       "5253      0  日本によってけんけんガクガクの議論を持たらされた韓国は被害者日本人がしっかり考えないと10億...\n",
       "5254      0  安楽死を合法にしたら若者殺到するんだろうなあ[SEP]ゴムボート買って沖まで漕いで行ったら?...\n",
       "5255      0  女は女の汚い部分も描きつつ男に理想をもつ男は男を美化しつつ女に理想をもつ[SEP]男は美化し...\n",
       "\n",
       "[5256 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[:, [\"label\", \"clean_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 繰り返し文字をどう抜いていくか\n",
    "* 単に繰り返し指定だと「ええんやで」が「えんやで」になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(´・ω・｀)ドキッ\\t(o'ω'n)「あああああああああああああああああああああああああああああああ！！！！！！！！！！！（ﾌﾞﾘﾌﾞﾘﾌﾞﾘﾌﾞﾘｭﾘｭﾘｭﾘｭﾘｭﾘｭ！！！！！！ﾌﾞﾂﾁﾁﾌﾞﾌﾞﾌﾞﾁﾁﾁﾁﾌﾞﾘﾘｲﾘﾌﾞﾌﾞﾌﾞﾌﾞｩｩｩｩｯｯｯ！！！！！！！）」\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = train_df.loc[210, \"original_text\"]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['あああああああああああああああああああああああああああああああ',\n",
       " '！！！！！！！！！！！',\n",
       " '！！！！！！',\n",
       " 'ﾁﾁ',\n",
       " 'ﾁﾁﾁﾁ',\n",
       " 'ﾘﾘ',\n",
       " 'ｩｩｩｩ',\n",
       " 'ｯｯｯ',\n",
       " '！！！！！！！']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nchars(t, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全件print(train) --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", 20000)\n",
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "# train_df.loc[train_df.isnull().sum(axis=1).sort_values().index, [\"label\", \"text\", \"original_text\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f007669f58917ef828e563fe3b1481c9ee4c6d5364b91c467fc73ebe5072978b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
