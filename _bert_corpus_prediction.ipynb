{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コーパスのデータを入力として学習済みモデルから予測結果を出力するnotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** SEED fixed : 42 ******\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, T5Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "\n",
    "from bert_utils import *\n",
    "from config import *\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算時のsettingはtrainで保存したjsonから読み込む --\n",
    "# run_idだけ指定 --\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--run_id\", type=str, default=\"tmp\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "save_path = f\"{input_root}corpus_label_{args.run_id}\"\n",
    "\n",
    "if not os.path.exists(f\"{save_path}\"):\n",
    "    os.mkdir(f\"{save_path}\")\n",
    "\n",
    "# settings, fine-tuningしたモデル, モデル作成時に前処理したtest_dfを読み込み -- \n",
    "output_path = f\"{output_root}{args.run_id}/\"\n",
    "settings = pd.read_json(f\"{output_path}settings.json\", typ=\"series\")\n",
    "model_paths = glob(f\"{settings.output_path}*.pth\"); model_paths.sort()\n",
    "\n",
    "# define tokenizer --\n",
    "tokenizer = define_tokenizer(settings.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象とするデータの読み込み --\n",
    "corpus_paths = glob(f\"{input_root}*.feather\")\n",
    "\n",
    "df = []\n",
    "for corpus_path in corpus_paths:\n",
    "    _df = pd.read_feather(corpus_path)\n",
    "    _df = _df.reset_index(drop=False, names=\"id\")\n",
    "    _df[\"id\"] = corpus_path.split(\"/\")[-1].split(\".\")[0] + \"_\" + _df[\"id\"].astype(str)\n",
    "    df.append(_df)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18589859, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug --\n",
    "df = df.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test preds --\n",
    "test_dataset = HateSpeechDataset(\n",
    "    df, tokenizer=tokenizer, \n",
    "    max_length=settings.max_length, num_classes=settings.num_classes, \n",
    "    text_col=\"clean_text\", isTrain=False\n",
    "    )\n",
    "#test_loader = DataLoader(test_dataset, batch_size=settings.test_batch_size, num_workers=2, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, num_workers=2, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmax_pooling\u001b[39m\n",
      "Getting predictions for model : /mnt/sdb/NISHIKA_DATA/hate-speech-detection/output/tmp/model-fold0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [01:39<00:00,  1.01s/it]\n",
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmax_pooling\u001b[39m\n",
      "Getting predictions for model : /mnt/sdb/NISHIKA_DATA/hate-speech-detection/output/tmp/model-fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [01:39<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "for fold in range(0, settings.folds):\n",
    "    model_id = \"model\"\n",
    "    preds = inference(settings.model_name, settings.num_classes, settings.model_custom_header, model_paths[fold], test_loader, device)\n",
    "    preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = np.mean(np.array(preds_list), axis=0)\n",
    "df[f\"{model_id}_pred\"] = np.argmax(final_preds, axis=1)\n",
    "for _class in range(0, settings.num_classes):\n",
    "    df.loc[:, f\"{model_id}_oof_class_{_class}\"] = final_preds[:, _class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"{save_path}/corpus_labeled.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>model_pred</th>\n",
       "      <th>model_oof_class_0</th>\n",
       "      <th>model_oof_class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news4vip_0</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>医者ああ正常なコミュニケーションが取れてませんねえ・・・医者月一で病院に来てください申請しま...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950779</td>\n",
       "      <td>0.049221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news4vip_1</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>自立支援手帳じゃなくて障害者手帳ですか?療育?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.898060</td>\n",
       "      <td>0.101940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news4vip_2</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>なにその全く実用性がない特殊能力</td>\n",
       "      <td>0</td>\n",
       "      <td>0.844515</td>\n",
       "      <td>0.155485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news4vip_3</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>本人が発達障害の自覚がないと職場では単純に使えない奴で疎まれるそうならないように周りを誘導す...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.870264</td>\n",
       "      <td>0.129736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news4vip_4</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>いや発達はさ環境が支えてくれればしっかり労働出来るじゃんしかも悪気は元無いんだし人間的には嫌...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.159069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>news4vip_99995</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>コミュ障死ね(笑)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890367</td>\n",
       "      <td>0.109633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>news4vip_99996</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>は!?コンビニの店員となに話すんだよwwww</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944303</td>\n",
       "      <td>0.055697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>news4vip_99997</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>数十秒やん</td>\n",
       "      <td>0</td>\n",
       "      <td>0.940866</td>\n",
       "      <td>0.059134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>news4vip_99998</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>パスタ系は2分くらい待つよ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930972</td>\n",
       "      <td>0.069028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>news4vip_99999</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>山陰に遊びにいっていい?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944927</td>\n",
       "      <td>0.055073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id    source  \\\n",
       "0          news4vip_0  news4vip   \n",
       "1          news4vip_1  news4vip   \n",
       "2          news4vip_2  news4vip   \n",
       "3          news4vip_3  news4vip   \n",
       "4          news4vip_4  news4vip   \n",
       "...               ...       ...   \n",
       "99995  news4vip_99995  news4vip   \n",
       "99996  news4vip_99996  news4vip   \n",
       "99997  news4vip_99997  news4vip   \n",
       "99998  news4vip_99998  news4vip   \n",
       "99999  news4vip_99999  news4vip   \n",
       "\n",
       "                                              clean_text  model_pred  \\\n",
       "0      医者ああ正常なコミュニケーションが取れてませんねえ・・・医者月一で病院に来てください申請しま...           0   \n",
       "1                                自立支援手帳じゃなくて障害者手帳ですか?療育?           0   \n",
       "2                                       なにその全く実用性がない特殊能力           0   \n",
       "3      本人が発達障害の自覚がないと職場では単純に使えない奴で疎まれるそうならないように周りを誘導す...           0   \n",
       "4      いや発達はさ環境が支えてくれればしっかり労働出来るじゃんしかも悪気は元無いんだし人間的には嫌...           0   \n",
       "...                                                  ...         ...   \n",
       "99995                                          コミュ障死ね(笑)           0   \n",
       "99996                             は!?コンビニの店員となに話すんだよwwww           0   \n",
       "99997                                              数十秒やん           0   \n",
       "99998                                      パスタ系は2分くらい待つよ           0   \n",
       "99999                                       山陰に遊びにいっていい?           0   \n",
       "\n",
       "       model_oof_class_0  model_oof_class_1  \n",
       "0               0.950779           0.049221  \n",
       "1               0.898060           0.101940  \n",
       "2               0.844515           0.155485  \n",
       "3               0.870264           0.129736  \n",
       "4               0.840931           0.159069  \n",
       "...                  ...                ...  \n",
       "99995           0.890367           0.109633  \n",
       "99996           0.944303           0.055697  \n",
       "99997           0.940866           0.059134  \n",
       "99998           0.930972           0.069028  \n",
       "99999           0.944927           0.055073  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f007669f58917ef828e563fe3b1481c9ee4c6d5364b91c467fc73ebe5072978b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
